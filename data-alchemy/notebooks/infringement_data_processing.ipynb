{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# ðŸ”® Traffic Infringement Data Processing\n",
				"\n",
				"This notebook processes raw traffic infringement data and converts it into the GeoJSON format required for the heatmap visualization.\n",
				"\n",
				"## Overview\n",
				"\n",
				"1. Load raw data\n",
				"2. Clean and preprocess\n",
				"3. Geocode locations\n",
				"4. Transform to GeoJSON\n",
				"5. Export for visualization"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Import necessary libraries\n",
				"import pandas as pd\n",
				"import numpy as np\n",
				"import matplotlib.pyplot as plt\n",
				"import json\n",
				"import os\n",
				"from pathlib import Path"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 1. Load Raw Data\n",
				"\n",
				"First, let's load the traffic infringement data from the CSV file."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Set paths\n",
				"ROOT_DIR = Path('../../')\n",
				"DATA_DIR = ROOT_DIR / 'data'\n",
				"OUTPUT_DIR = Path('../output')\n",
				"\n",
				"# Create output directory if it doesn't exist\n",
				"os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
				"\n",
				"# Load the traffic infringements data\n",
				"infringements_path = DATA_DIR / 'trafficinfringementsissued.csv'\n",
				"df = pd.read_csv(infringements_path, header=0)\n",
				"\n",
				"# Display the first few rows\n",
				"df.head()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Basic data exploration\n",
				"print(f\"Dataset shape: {df.shape}\")\n",
				"df.info()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 2. Clean and Preprocess Data\n",
				"\n",
				"We need to clean the data and prepare it for geocoding."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Clean column names (remove spaces, lowercase)\n",
				"df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
				"\n",
				"# Show columns after cleaning\n",
				"df.columns"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Check for missing values\n",
				"print(\"Missing values by column:\")\n",
				"df.isna().sum()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 3. Geocoding\n",
				"\n",
				"We need to convert location names to coordinates. Let's use a dictionary mapping locations to coordinates."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# This is a simplified approach - for a real project you would use a geocoding service\n",
				"# or a more comprehensive dataset of Australian locations with coordinates\n",
				"\n",
				"# Example mapping of Queensland regions to approximate coordinates\n",
				"qld_regions = {\n",
				"    'BRISBANE': {'lat': -27.4698, 'lon': 153.0251},\n",
				"    'GOLD COAST': {'lat': -28.0167, 'lon': 153.4000},\n",
				"    'SUNSHINE COAST': {'lat': -26.6500, 'lon': 153.0667},\n",
				"    'LOGAN': {'lat': -27.6392, 'lon': 153.1086},\n",
				"    'IPSWICH': {'lat': -27.6161, 'lon': 152.7610},\n",
				"    'CAIRNS': {'lat': -16.9186, 'lon': 145.7781},\n",
				"    'TOWNSVILLE': {'lat': -19.2590, 'lon': 146.8169},\n",
				"    'TOOWOOMBA': {'lat': -27.5598, 'lon': 151.9507},\n",
				"    'MACKAY': {'lat': -21.1412, 'lon': 149.1868},\n",
				"    'ROCKHAMPTON': {'lat': -23.3791, 'lon': 150.5100},\n",
				"    'BUNDABERG': {'lat': -24.8500, 'lon': 152.3500},\n",
				"    'HERVEY BAY': {'lat': -25.2882, 'lon': 152.8730},\n",
				"    'GLADSTONE': {'lat': -23.8430, 'lon': 151.2583},\n",
				"    'MARYBOROUGH': {'lat': -25.5378, 'lon': 152.7020},\n",
				"    'MOUNT ISA': {'lat': -20.7256, 'lon': 139.4927},\n",
				"    # Add more regions as needed\n",
				"}"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Check which locations we have in the data\n",
				"locations = df['district'].unique()\n",
				"print(f\"Locations in the dataset: {len(locations)}\")\n",
				"locations[:20]  # Show the first 20"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Function to add coordinates to the dataframe\n",
				"def add_coordinates(row):\n",
				"    location = row['district']\n",
				"    if location in qld_regions:\n",
				"        return pd.Series([qld_regions[location]['lat'], qld_regions[location]['lon']])\n",
				"    else:\n",
				"        # Default to Brisbane for unknown locations - you may want to handle this differently\n",
				"        return pd.Series([None, None])\n",
				"\n",
				"# Apply the function to add latitude and longitude columns\n",
				"df[['latitude', 'longitude']] = df.apply(add_coordinates, axis=1)\n",
				"\n",
				"# Check how many locations were successfully geocoded\n",
				"print(f\"Locations with coordinates: {df['latitude'].notna().sum()} out of {len(df)}\")\n",
				"\n",
				"# Display sample with coordinates\n",
				"df[df['latitude'].notna()].head()"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 4. Aggregate Data\n",
				"\n",
				"Now, let's aggregate the data by location to get the total number of infringements per location."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Group by location and sum the number of infringements\n",
				"location_counts = df.groupby(['district', 'latitude', 'longitude'])['count'].sum().reset_index()\n",
				"\n",
				"# Sort by count in descending order\n",
				"location_counts = location_counts.sort_values('count', ascending=False)\n",
				"\n",
				"# Display the top locations by infringement count\n",
				"location_counts.head(10)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 5. Transform to GeoJSON\n",
				"\n",
				"Now let's convert our aggregated data to GeoJSON format for the heatmap."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Function to normalize values to a 0-100 scale for intensity\n",
				"def normalize_values(series):\n",
				"    min_val = series.min()\n",
				"    max_val = series.max()\n",
				"    return 100 * (series - min_val) / (max_val - min_val)\n",
				"\n",
				"# Normalize the counts to get intensity values between 0-100\n",
				"location_counts['intensity'] = normalize_values(location_counts['count'])\n",
				"\n",
				"# Remove rows with missing coordinates\n",
				"geo_data = location_counts.dropna(subset=['latitude', 'longitude'])\n",
				"\n",
				"# Create GeoJSON feature collection\n",
				"features = []\n",
				"for _, row in geo_data.iterrows():\n",
				"    feature = {\n",
				"        \"type\": \"Feature\",\n",
				"        \"properties\": {\n",
				"            \"intensity\": float(row['intensity']),\n",
				"            \"location\": row['district'],\n",
				"            \"count\": int(row['count'])\n",
				"        },\n",
				"        \"geometry\": {\n",
				"            \"type\": \"Point\",\n",
				"            \"coordinates\": [float(row['longitude']), float(row['latitude'])]\n",
				"        }\n",
				"    }\n",
				"    features.append(feature)\n",
				"\n",
				"# Create the GeoJSON structure\n",
				"geojson_data = {\n",
				"    \"type\": \"FeatureCollection\",\n",
				"    \"features\": features\n",
				"}\n",
				"\n",
				"# Preview the first feature\n",
				"geojson_data[\"features\"][0]"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Save the GeoJSON data to a file\n",
				"output_file = OUTPUT_DIR / 'infringements.json'\n",
				"with open(output_file, 'w') as f:\n",
				"    json.dump(geojson_data, f, indent=2)\n",
				"\n",
				"print(f\"GeoJSON data saved to {output_file}\")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Also save a CSV version for compatibility\n",
				"csv_output = OUTPUT_DIR / 'infringements.csv'\n",
				"geo_data[['latitude', 'longitude', 'intensity']].to_csv(csv_output, index=False)\n",
				"print(f\"CSV data saved to {csv_output}\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 6. Copy to Web App\n",
				"\n",
				"Finally, let's copy the processed files to the client/data directory so they can be used by the web application."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"import shutil\n",
				"\n",
				"# Define paths\n",
				"client_data_dir = ROOT_DIR / 'client' / 'data'\n",
				"\n",
				"# Ensure the client data directory exists\n",
				"os.makedirs(client_data_dir, exist_ok=True)\n",
				"\n",
				"# Copy the GeoJSON file\n",
				"shutil.copy(output_file, client_data_dir / 'data.json')\n",
				"\n",
				"# Copy the CSV file\n",
				"shutil.copy(csv_output, client_data_dir / 'data.csv')\n",
				"\n",
				"print(f\"Files copied to web app directory: {client_data_dir}\")"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## 7. Visualization\n",
				"\n",
				"Let's create a simple visualization to preview how our data might look on a map."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"source": [
				"# Install and import folium if needed\n",
				"import folium\n",
				"from folium.plugins import HeatMap\n",
				"\n",
				"# Create a base map centered on Australia\n",
				"m = folium.Map(location=[-25.2744, 133.7751], zoom_start=4)\n",
				"\n",
				"# Prepare data for heatmap\n",
				"heat_data = [[row['latitude'], row['longitude'], row['intensity']] for _, row in geo_data.iterrows()]\n",
				"\n",
				"# Add the heatmap\n",
				"HeatMap(heat_data).add_to(m)\n",
				"\n",
				"# Save the map\n",
				"map_file = OUTPUT_DIR / 'preview_map.html'\n",
				"m.save(map_file)\n",
				"\n",
				"print(f\"Preview map saved to {map_file}\")\n",
				"m"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.9.0"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
