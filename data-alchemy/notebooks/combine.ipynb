{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”® Combining Traffic Data for Visualization\n",
    "\n",
    "This notebook combines the processed traffic infringement and mobile speed camera datasets into a unified format with additional filtering fields.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Load processed datasets\n",
    "2. Standardize properties\n",
    "3. Add district/region information\n",
    "4. Create unified dataset\n",
    "5. Export for visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Processed Datasets\n",
    "\n",
    "First, we'll load the processed GeoJSON files for infringements and speed cameras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 infringement features\n",
      "Loaded 314 camera features\n"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "ROOT_DIR = Path('../')\n",
    "OUTPUT_DIR = ROOT_DIR / 'output'\n",
    "COMBINED_DIR = OUTPUT_DIR / 'combined'\n",
    "CLIENT_DATA_DIR = ROOT_DIR / '..' / 'client' / 'data'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(COMBINED_DIR, exist_ok=True)\n",
    "os.makedirs(CLIENT_DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Load GeoJSON files\n",
    "with open(OUTPUT_DIR / 'infringements.json', 'r') as f:\n",
    "    infringements_geojson = json.load(f)\n",
    "\n",
    "with open(OUTPUT_DIR / 'speed_cameras.json', 'r') as f:\n",
    "    cameras_geojson = json.load(f)\n",
    "\n",
    "# Preview feature counts\n",
    "print(f\"Loaded {len(infringements_geojson['features'])} infringement features\")\n",
    "print(f\"Loaded {len(cameras_geojson['features'])} camera features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standardize Properties\n",
    "\n",
    "Next, we'll standardize the property fields across both datasets to ensure consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infringements properties sample:\n",
      "{\n",
      "  \"intensity\": 100.0,\n",
      "  \"location\": \"NORTH BRISBANE\",\n",
      "  \"count\": 7541\n",
      "}\n",
      "\n",
      "Speed cameras properties sample:\n",
      "{\n",
      "  \"intensity\": 100.0,\n",
      "  \"location\": \"Monaro Highway\",\n",
      "  \"visits\": 3774,\n",
      "  \"hours\": 5040.99,\n",
      "  \"checked\": 4421729\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Examine the property structure of each dataset\n",
    "print(\"Infringements properties sample:\")\n",
    "print(json.dumps(infringements_geojson['features'][0]['properties'], indent=2))\n",
    "print(\"\\nSpeed cameras properties sample:\")\n",
    "print(json.dumps(cameras_geojson['features'][0]['properties'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardized infringement example:\n",
      "{\n",
      "  \"intensity\": 100.0,\n",
      "  \"location\": \"NORTH BRISBANE\",\n",
      "  \"count\": 7541,\n",
      "  \"data_type\": \"infringement\",\n",
      "  \"district\": \"NORTH BRISBANE\",\n",
      "  \"region\": \"Queensland\",\n",
      "  \"visits\": null,\n",
      "  \"hours\": null,\n",
      "  \"checked\": null\n",
      "}\n",
      "\n",
      "Standardized camera example:\n",
      "{\n",
      "  \"intensity\": 100.0,\n",
      "  \"location\": \"Monaro Highway\",\n",
      "  \"visits\": 3774,\n",
      "  \"hours\": 5040.99,\n",
      "  \"checked\": 4421729,\n",
      "  \"data_type\": \"speed_camera\",\n",
      "  \"district\": \"ACT South\",\n",
      "  \"region\": \"Australian Capital Territory\",\n",
      "  \"count\": 3774\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Function to standardize properties for each dataset\n",
    "def standardize_infringement_properties(feature):\n",
    "    props = feature['properties']\n",
    "    \n",
    "    # Add data type identifier\n",
    "    props['data_type'] = 'infringement'\n",
    "    \n",
    "    # Rename fields for consistency\n",
    "    if 'location' in props:\n",
    "        props['district'] = props['location']\n",
    "        props['region'] = 'Queensland'  # Add region information\n",
    "        \n",
    "    # Add empty fields that exist in the other dataset for consistency\n",
    "    if 'visits' not in props:\n",
    "        props['visits'] = None\n",
    "    if 'hours' not in props:\n",
    "        props['hours'] = None\n",
    "    if 'checked' not in props:\n",
    "        props['checked'] = None\n",
    "        \n",
    "    # Ensure all records have intensity values\n",
    "    if 'intensity' not in props and 'count' in props:\n",
    "        # We're keeping the original intensity calculation\n",
    "        props['intensity'] = props.get('intensity', float(props['count']))\n",
    "        \n",
    "    return feature\n",
    "\n",
    "def standardize_camera_properties(feature):\n",
    "    props = feature['properties']\n",
    "    \n",
    "    # Add data type identifier\n",
    "    props['data_type'] = 'speed_camera'\n",
    "    \n",
    "    # Assign district based on location grouping\n",
    "    # For ACT locations, we'll map them to districts\n",
    "    props['district'] = 'ACT'  # Default district\n",
    "    \n",
    "    # You could add more specific district mapping here based on coordinates or other data\n",
    "    # For example, you could divide Canberra into North, South, East, West districts\n",
    "    # This is a simplified example - you may want to develop a more sophisticated mapping\n",
    "    coords = feature['geometry']['coordinates']\n",
    "    lat = coords[1]\n",
    "    lon = coords[0]\n",
    "    \n",
    "    # Simple district assignment based on coordinates (customize as needed)\n",
    "    if lat < -35.3:\n",
    "        props['district'] = 'ACT South'\n",
    "    elif lat > -35.2:\n",
    "        props['district'] = 'ACT North'\n",
    "    else:\n",
    "        props['district'] = 'ACT Central'\n",
    "    \n",
    "    props['region'] = 'Australian Capital Territory'\n",
    "    \n",
    "    # Add empty fields that exist in the other dataset for consistency\n",
    "    if 'count' not in props:\n",
    "        props['count'] = props.get('visits', 0)\n",
    "        \n",
    "    return feature\n",
    "\n",
    "# Apply the standardization functions\n",
    "standardized_infringements = [standardize_infringement_properties(feature) \n",
    "                              for feature in infringements_geojson['features']]\n",
    "standardized_cameras = [standardize_camera_properties(feature) \n",
    "                       for feature in cameras_geojson['features']]\n",
    "\n",
    "# Check the results\n",
    "print(\"\\nStandardized infringement example:\")\n",
    "print(json.dumps(standardized_infringements[0]['properties'], indent=2))\n",
    "print(\"\\nStandardized camera example:\")\n",
    "print(json.dumps(standardized_cameras[0]['properties'], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Additional Filtering Fields\n",
    "\n",
    "Now we'll add additional fields that will be useful for filtering in the visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhanced infringement example:\n",
      "{\n",
      "  \"intensity\": 100.0,\n",
      "  \"location\": \"NORTH BRISBANE\",\n",
      "  \"count\": 7541,\n",
      "  \"data_type\": \"infringement\",\n",
      "  \"district\": \"NORTH BRISBANE\",\n",
      "  \"region\": \"Queensland\",\n",
      "  \"visits\": null,\n",
      "  \"hours\": null,\n",
      "  \"checked\": null,\n",
      "  \"intensity_category\": \"Very High\",\n",
      "  \"frequency\": \"Very High\"\n",
      "}\n",
      "\n",
      "Enhanced camera example:\n",
      "{\n",
      "  \"intensity\": 100.0,\n",
      "  \"location\": \"Monaro Highway\",\n",
      "  \"visits\": 3774,\n",
      "  \"hours\": 5040.99,\n",
      "  \"checked\": 4421729,\n",
      "  \"data_type\": \"speed_camera\",\n",
      "  \"district\": \"ACT South\",\n",
      "  \"region\": \"Australian Capital Territory\",\n",
      "  \"count\": 3774,\n",
      "  \"intensity_category\": \"Very High\",\n",
      "  \"frequency\": \"Very Frequent\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define a function to add categories based on intensity or other properties\n",
    "def add_filtering_fields(feature):\n",
    "    props = feature['properties']\n",
    "    \n",
    "    # Add intensity category\n",
    "    intensity = props.get('intensity', 0)\n",
    "    if intensity >= 80:\n",
    "        props['intensity_category'] = 'Very High'\n",
    "    elif intensity >= 60:\n",
    "        props['intensity_category'] = 'High'\n",
    "    elif intensity >= 40:\n",
    "        props['intensity_category'] = 'Medium'\n",
    "    elif intensity >= 20:\n",
    "        props['intensity_category'] = 'Low'\n",
    "    else:\n",
    "        props['intensity_category'] = 'Very Low'\n",
    "    \n",
    "    # For speed cameras, add a category based on visit frequency\n",
    "    if props['data_type'] == 'speed_camera' and 'visits' in props and props['visits']:\n",
    "        visits = props['visits']\n",
    "        if visits >= 1000:\n",
    "            props['frequency'] = 'Very Frequent'\n",
    "        elif visits >= 500:\n",
    "            props['frequency'] = 'Frequent'\n",
    "        elif visits >= 250:\n",
    "            props['frequency'] = 'Regular'\n",
    "        elif visits >= 100:\n",
    "            props['frequency'] = 'Occasional'\n",
    "        else:\n",
    "            props['frequency'] = 'Rare'\n",
    "    \n",
    "    # For infringements, add a category based on count\n",
    "    if props['data_type'] == 'infringement' and 'count' in props and props['count']:\n",
    "        count = props['count']\n",
    "        if count >= 5000:\n",
    "            props['frequency'] = 'Very High'\n",
    "        elif count >= 3000:\n",
    "            props['frequency'] = 'High'\n",
    "        elif count >= 1000:\n",
    "            props['frequency'] = 'Medium'\n",
    "        elif count >= 500:\n",
    "            props['frequency'] = 'Low'\n",
    "        else:\n",
    "            props['frequency'] = 'Very Low'\n",
    "    \n",
    "    return feature\n",
    "\n",
    "# Apply the filtering fields function\n",
    "enhanced_infringements = [add_filtering_fields(feature) for feature in standardized_infringements]\n",
    "enhanced_cameras = [add_filtering_fields(feature) for feature in standardized_cameras]\n",
    "\n",
    "# Check the results\n",
    "print(\"\\nEnhanced infringement example:\")\n",
    "print(json.dumps(enhanced_infringements[0]['properties'], indent=2))\n",
    "print(\"\\nEnhanced camera example:\")\n",
    "print(json.dumps(enhanced_cameras[0]['properties'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random weather and time-of-day information to the data\n",
    "import random\n",
    "\n",
    "def add_environmental_factors(feature):\n",
    "    props = feature['properties']\n",
    "    \n",
    "    # Add random weather condition (80% dry, 20% rainy - adjust as needed)\n",
    "    weather_rand = random.random()\n",
    "    if weather_rand < 0.8:\n",
    "        props['weather'] = 'Dry'\n",
    "    else:\n",
    "        props['weather'] = 'Rainy'\n",
    "    \n",
    "    # Add random time of day (70% day, 30% night - adjust as needed)\n",
    "    time_rand = random.random()\n",
    "    if time_rand < 0.7:\n",
    "        props['time_of_day'] = 'Day'\n",
    "    else:\n",
    "        props['time_of_day'] = 'Night'\n",
    "    \n",
    "    # Optionally add more specific time periods\n",
    "    hour_rand = random.randint(0, 23)\n",
    "    if 6 <= hour_rand < 12:\n",
    "        props['time_period'] = 'Morning'\n",
    "    elif 12 <= hour_rand < 18:\n",
    "        props['time_period'] = 'Afternoon'\n",
    "    elif 18 <= hour_rand < 22:\n",
    "        props['time_period'] = 'Evening'\n",
    "    else:\n",
    "        props['time_period'] = 'Late Night'\n",
    "    \n",
    "    return feature\n",
    "\n",
    "# Apply environmental factors to both datasets\n",
    "enhanced_infringements = [add_environmental_factors(feature) for feature in enhanced_infringements]\n",
    "enhanced_cameras = [add_environmental_factors(feature) for feature in enhanced_cameras]\n",
    "\n",
    "# Check the results with the added environmental factors\n",
    "print(\"\\nInfringement example with environmental factors:\")\n",
    "print(json.dumps(enhanced_infringements[0]['properties'], indent=2))\n",
    "print(\"\\nCamera example with environmental factors:\")\n",
    "print(json.dumps(enhanced_cameras[0]['properties'], indent=2))\n",
    "\n",
    "# Add some summary statistics about the environmental factors\n",
    "infringement_weather = [f['properties']['weather'] for f in enhanced_infringements]\n",
    "camera_weather = [f['properties']['weather'] for f in enhanced_cameras]\n",
    "\n",
    "print(\"\\nWeather distribution:\")\n",
    "print(f\"Infringements: Dry: {infringement_weather.count('Dry')}, Rainy: {infringement_weather.count('Rainy')}\")\n",
    "print(f\"Speed Cameras: Dry: {camera_weather.count('Dry')}, Rainy: {camera_weather.count('Rainy')}\")\n",
    "\n",
    "infringement_time = [f['properties']['time_of_day'] for f in enhanced_infringements]\n",
    "camera_time = [f['properties']['time_of_day'] for f in enhanced_cameras]\n",
    "\n",
    "print(\"\\nTime of day distribution:\")\n",
    "print(f\"Infringements: Day: {infringement_time.count('Day')}, Night: {infringement_time.count('Night')}\")\n",
    "print(f\"Speed Cameras: Day: {camera_time.count('Day')}, Night: {camera_time.count('Night')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Unified Dataset\n",
    "\n",
    "Now we'll combine both datasets into a unified GeoJSON file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset contains 329 features\n",
      "\n",
      "Data type distribution:\n",
      "infringement: 15 features\n",
      "speed_camera: 314 features\n",
      "\n",
      "District distribution:\n",
      "ACT South: 171 features\n",
      "ACT Central: 116 features\n",
      "ACT North: 27 features\n",
      "NORTH BRISBANE: 1 features\n",
      "SOUTH BRISBANE: 1 features\n",
      "GOLD COAST: 1 features\n",
      "CAPRICORNIA: 1 features\n",
      "SUNSHINE COAST: 1 features\n",
      "FAR NORTH: 1 features\n",
      "LOGAN: 1 features\n"
     ]
    }
   ],
   "source": [
    "# Combine the features\n",
    "combined_features = enhanced_infringements + enhanced_cameras\n",
    "\n",
    "# Create the unified GeoJSON\n",
    "unified_geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": combined_features\n",
    "}\n",
    "\n",
    "print(f\"Combined dataset contains {len(unified_geojson['features'])} features\")\n",
    "\n",
    "# Check distribution of data types\n",
    "data_types = {}\n",
    "for feature in unified_geojson['features']:\n",
    "    data_type = feature['properties']['data_type']\n",
    "    data_types[data_type] = data_types.get(data_type, 0) + 1\n",
    "    \n",
    "print(\"\\nData type distribution:\")\n",
    "for data_type, count in data_types.items():\n",
    "    print(f\"{data_type}: {count} features\")\n",
    "\n",
    "# Check distribution of districts\n",
    "districts = {}\n",
    "for feature in unified_geojson['features']:\n",
    "    district = feature['properties'].get('district', 'Unknown')\n",
    "    districts[district] = districts.get(district, 0) + 1\n",
    "    \n",
    "print(\"\\nDistrict distribution:\")\n",
    "sorted_districts = sorted(districts.items(), key=lambda x: x[1], reverse=True)\n",
    "for district, count in sorted_districts[:10]:  # Show top 10\n",
    "    print(f\"{district}: {count} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export for Visualization\n",
    "\n",
    "Finally, we'll save the unified dataset to a file for use in the visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved unified GeoJSON to ../output/combined/traffic_data_unified.json\n",
      "Saved unified CSV to ../output/combined/traffic_data_unified.csv\n",
      "Copied files to web app directory: ../../client/data\n"
     ]
    }
   ],
   "source": [
    "# Save the unified GeoJSON\n",
    "unified_geojson_path = COMBINED_DIR / 'traffic_data_unified.json'\n",
    "with open(unified_geojson_path, 'w') as f:\n",
    "    json.dump(unified_geojson, f, indent=2)\n",
    "\n",
    "print(f\"Saved unified GeoJSON to {unified_geojson_path}\")\n",
    "\n",
    "# Create a simplified CSV version with key fields for backup/alternative use\n",
    "# Convert to DataFrame for easier CSV export\n",
    "rows = []\n",
    "for feature in unified_geojson['features']:\n",
    "    props = feature['properties']\n",
    "    coords = feature['geometry']['coordinates']\n",
    "    row = {\n",
    "        'data_type': props.get('data_type', ''),\n",
    "        'district': props.get('district', ''),\n",
    "        'region': props.get('region', ''),\n",
    "        'intensity': props.get('intensity', 0),\n",
    "        'intensity_category': props.get('intensity_category', ''),\n",
    "        'frequency': props.get('frequency', ''),\n",
    "        'count': props.get('count', 0) if props.get('count') is not None else 0,\n",
    "        'visits': props.get('visits', 0) if props.get('visits') is not None else 0,\n",
    "        'weather': props.get('weather', ''),\n",
    "        'time_of_day': props.get('time_of_day', ''),\n",
    "        'time_period': props.get('time_period', ''),\n",
    "        'longitude': coords[0],\n",
    "        'latitude': coords[1]\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "unified_csv_path = COMBINED_DIR / 'traffic_data_unified.csv'\n",
    "df.to_csv(unified_csv_path, index=False)\n",
    "print(f\"Saved unified CSV to {unified_csv_path}\")\n",
    "\n",
    "# Copy to client data directory for the web app\n",
    "import shutil\n",
    "shutil.copy(unified_geojson_path, CLIENT_DATA_DIR / 'data.json')\n",
    "shutil.copy(unified_csv_path, CLIENT_DATA_DIR / 'data.csv')\n",
    "print(f\"Copied files to web app directory: {CLIENT_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Overview Statistics\n",
    "\n",
    "Let's create some summary statistics that might be useful for the visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics by region and data type:\n",
      "                         region     data_type  count  visits  num_districts\n",
      "0  Australian Capital Territory  speed_camera  83486   83486              3\n",
      "1                    Queensland  infringement  70102       0             15\n",
      "\n",
      "Saved and copied summary statistics\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics by region\n",
    "region_stats = df.groupby(['region', 'data_type']).agg({\n",
    "    'count': 'sum',\n",
    "    'visits': 'sum',\n",
    "    'district': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "region_stats = region_stats.rename(columns={'district': 'num_districts'})\n",
    "\n",
    "# Calculate weather statistics\n",
    "weather_stats = df.groupby(['weather', 'data_type']).size().reset_index(name='count')\n",
    "time_stats = df.groupby(['time_of_day', 'data_type']).size().reset_index(name='count')\n",
    "period_stats = df.groupby(['time_period', 'data_type']).size().reset_index(name='count')\n",
    "\n",
    "# Display the statistics\n",
    "print(\"Statistics by region and data type:\")\n",
    "print(region_stats)\n",
    "\n",
    "print(\"\\nStatistics by weather and data type:\")\n",
    "print(weather_stats)\n",
    "\n",
    "print(\"\\nStatistics by time of day and data type:\")\n",
    "print(time_stats)\n",
    "\n",
    "# Save summary statistics to a JSON file\n",
    "summary = {\n",
    "    'total_points': len(df),\n",
    "    'data_types': data_types,\n",
    "    'regions': df['region'].nunique(),\n",
    "    'districts': df['district'].nunique(),\n",
    "    'region_stats': region_stats.to_dict(orient='records'),\n",
    "    'weather_stats': weather_stats.to_dict(orient='records'),\n",
    "    'time_stats': time_stats.to_dict(orient='records'),\n",
    "    'period_stats': period_stats.to_dict(orient='records')\n",
    "}\n",
    "\n",
    "summary_path = COMBINED_DIR / 'traffic_data_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# Copy to client data directory\n",
    "shutil.copy(summary_path, CLIENT_DATA_DIR / 'traffic_data_summary.json')\n",
    "print(f\"\\nSaved and copied summary statistics with environmental factors\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
